#!/home/chad/anaconda3/envs/tfgpu/bin/python

import setproctitle as spt
spt.setproctitle('cnvlstminfer')

import sys,os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
from tensorflow.keras import models
import matplotlib.pyplot as plt
import importlib

############################################################################
# READ INPUT CLASS and SET UP OUTPUT DIR
modulename = sys.argv[1].split('.')[0] # name of the input deck class file
inputDeckModule = importlib.import_module(modulename)
deck = inputDeckModule.params()
outputDir = deck.caseName

model = models.load_model(outputDir+'/model.h5',compile=False)
x = np.load(outputDir+'/valid_in.npy')
y = np.load(outputDir+'/valid_out.npy')
yh = model.predict(x)
num = np.linalg.norm(y-yh,axis=(1,2))
den = np.linalg.norm(y,axis=(1,2))
print(np.mean(num/den))

print(x.shape)
print(y.shape)
print(yh.shape)


imagesDir = deck.caseName+'/images'
if not os.path.exists(imagesDir):
    os.mkdir(imagesDir)

cols = 2
rows = y.shape[1]
for i in range(yh.shape[0]):
#for i in range(100):
    for j in range(rows):
        plt.subplot(rows,cols,2*j+1)
        plt.imshow(y[i,j].squeeze())
        plt.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False,labeltop=False)
        plt.tick_params(axis='y',which='both',left=False,right=False,labelleft=False,labelright=False)

        plt.subplot(rows,cols,2*j+2)
        plt.imshow(yh[i,j].squeeze())
        plt.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False,labeltop=False)
        plt.tick_params(axis='y',which='both',left=False,right=False,labelleft=False,labelright=False)
    #print(np.linalg.norm(yh[i,0]-yh[-1,2]))
    plt.savefig('%s/frame_%03i'%(imagesDir,i))
